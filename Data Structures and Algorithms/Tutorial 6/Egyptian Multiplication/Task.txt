Egyptian Multiplication
In this challenge we will get some more practice with recursion.  First, we will write a recursive function to multiply two numbers together.  We will assume throughout that both numbers are non-negative.  We could break down multiplication in a similar way to how we did the factorial function:

ğ‘¥
 
â‹…
 
ğ‘¦
 
=
{
0
if 
ğ‘¦
=
0
ğ‘¥
+
ğ‘¥
â‹…
(
ğ‘¦
âˆ’
1
)
otherwise
x â‹… y ={ 
0
x+xâ‹…(yâˆ’1)
â€‹
  
if y=0
otherwise
â€‹
 

The base case is when 
ğ‘¦
=
0
y=0, and we inexorably move towards the base case by decreasing 
ğ‘¦
y in every iteration.  

A problem with this algorithm is that we move towards the base case slowly.  We will have 
ğ‘¦
y recursive function calls, which is a lot of overhead and can cause a stack overflow for large values of 
ğ‘¦
y.

The ancient Egyptians came up with a recursive algorithm for multiplication where instead we repeatedly halve 
ğ‘¦
y rather than just subtracting 1 each time.  This algorithm only has about 
log
â¡
ğ‘¦
logy recursive calls.  This algorithm is based on the fact that if 
ğ‘¦
y is even, then

ğ‘¥
 
â‹…
 
ğ‘¦
 
=
 
(
ğ‘¥
+
ğ‘¥
)
â‹…
ğ‘¦
/
2
 if 
ğ‘¦
 even
x â‹… y = (x+x)â‹…y/2 if y even

Now in the recursive call we want to multiply 
ğ‘¥
+
ğ‘¥
x+x, which we can compute with one addition, with 
ğ‘¦
/
2
y/2.  If 
ğ‘¦
y is odd then (using the behaviour of / in C++, which truncates toward 0) we have

ğ‘¥
 
â‹…
 
ğ‘¦
 
=
 
ğ‘¥
+
(
ğ‘¥
+
ğ‘¥
)
â‹…
ğ‘¦
/
2
 if 
ğ‘¦
 odd
x â‹… y = x+(x+x)â‹…y/2 if y odd

Give a go implementing Egyptian multiplication in C++.


A cool thing about Egyptian multiplication is that the same algorithmic template can be used for other tasks.  Let's apply the same idea to computing the power of a number, that is the function power(x, a) which should return 
ğ‘¥
ğ‘
x 
a
 .  We will stick to the case where 
ğ‘¥
x is an integer and 
ğ‘
a is a non-negative integer.  Like the case of multiplication, we could easily do this iteratively in a for loop multiplying 
ğ‘¥
x by itself 
ğ‘
a times.  But this is guaranteed to take 
ğ‘
a iterations. We can apply the same halving idea here in a process known as  iterative squaring.  As we want to practice recursion, I will explain it in a recursive fashion.  For the base case, if a == 0 then pow(x,a) = 1.  If 
ğ‘
a is even then 

ğ‘¥
ğ‘
=
ğ‘¥
2
â‹…
ğ‘
/
2
=
(
ğ‘¥
2
)
ğ‘
/
2
=
pow
(
ğ‘¥
â‹…
ğ‘¥
,
ğ‘
/
2
)
x 
a
 =x 
2â‹…a/2
 =(x 
2
 ) 
a/2
 =pow(xâ‹…x,a/2)

With one multiplication we reduced the exponent in half!  Finally if 
ğ‘
a is odd then 

ğ‘¥
ğ‘
=
ğ‘¥
1
+
2
â‹…
(
ğ‘
âˆ’
1
)
/
2
=
ğ‘¥
â‹…
ğ‘¥
2
(
ğ‘
âˆ’
1
)
/
2
=
ğ‘¥
â‹…
pow
(
ğ‘¥
â‹…
ğ‘¥
,
 
(
ğ‘
âˆ’
1
)
/
2
)
x 
a
 =x 
1+2â‹…(aâˆ’1)/2
 =xâ‹…x 
2(aâˆ’1)/2
 =xâ‹…pow(xâ‹…x, (aâˆ’1)/2)

With repeated squaring we only do 
ğ‘‚
(
log
â¡
(
ğ‘
)
)
O(log(a)) multiplications instead of 
ğ‘
a.  See if you can implement these formulas as a recursive algorithm!

Bonus:
Compare the multiplication and powering algorithms.  Can you generalise these to a single algorithm that can take a function as input so that it can do both multiplication and powering?
